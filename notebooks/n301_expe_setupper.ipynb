{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup experiments: code, configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from consema.conformal import Conformalizer\n",
    "\n",
    "# from universeg import universeg  # installed via Makefile\n",
    "\n",
    "# model = universeg(pretrained=True)\n",
    "\n",
    "GPUNAME = \"cuda:0\"\n",
    "device_str = GPUNAME if torch.cuda.is_available() else \"cpu\"\n",
    "# device = torch.device(device_str)\n",
    "\n",
    "# _ = model.to(device)\n",
    "\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = RANDOM_SEED\n",
    "device_str = device_str\n",
    "score_funcs = [\"fixed_disk\", \"variable_disk\", \"thresholding\"]\n",
    "covratios = [0.99, 0.999, 0.99999]\n",
    "alphas = [0.05, 0.10]\n",
    "se_shapes = [\"cross\", \"square\"]\n",
    "\n",
    "\n",
    "chosen_nc_score = score_funcs[0]\n",
    "# chosen_nc_score = score_funcs[1]\n",
    "# chosen_nc_score = score_funcs[2]\n",
    "\n",
    "\n",
    "wbc_params = dict()\n",
    "oasis_params = {}\n",
    "polyps_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarkerie.datasets import setup_polyps\n",
    "\n",
    "(\n",
    "    calib_images,\n",
    "    calib_gt_arrays,\n",
    "    calib_pred_arrays,\n",
    "    test_images,\n",
    "    test_gt_arrays,\n",
    "    test_pred_arrays,\n",
    ") = setup_polyps(RANDOM_SEED, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_calib = tuple(\n",
    "    (img, gt, softpred)\n",
    "    for img, gt, softpred in zip(calib_images, calib_gt_arrays, calib_pred_arrays)\n",
    ")\n",
    "print(f\" --- n calibration points: {len(data_calib)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarkerie.models import PranetPolypsPrecomputedInferencer\n",
    "\n",
    "inferencer = PranetPolypsPrecomputedInferencer()\n",
    "se_params = dict(strict_radius=True)  # [3 X 3] cross\n",
    "cpred = Conformalizer(\n",
    "    inferencer=inferencer,\n",
    "    nonconformity_function_name=chosen_nc_score,\n",
    "    structuring_element_params=se_params,\n",
    ")\n",
    "\n",
    "covratio = 0.99\n",
    "confo_resu = cpred.compute_nonconformity_scores(data_calib, covratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "print(f\" --- Required coverage ratio = {covratio}\")\n",
    "print(f\" --- Probability of succes on test = {1 - alpha}\")\n",
    "print(f\" --- Chosen nonconformity score: {chosen_nc_score}\")\n",
    "cpred.plot_nc_scores(alpha_risk=alpha)\n",
    "cpred.plot_nc_scores_frequency(alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = tuple(\n",
    "    (img, gt, softpred)\n",
    "    for img, gt, softpred in zip(test_images, test_gt_arrays, test_pred_arrays)\n",
    ")\n",
    "\n",
    "print(f\" --- Required coverage ratio = {covratio}\")\n",
    "print(f\" --- Probability of succes on test = {1 - alpha}\")\n",
    "print()\n",
    "_test_preds = cpred.test_inferences(data_test)\n",
    "test_results = cpred.test_conformalization(_test_preds, alpha, covratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_coverage = np.mean(test_results.conformal_tests)\n",
    "empirical_covratio = np.mean(test_results.empirical_covratios)\n",
    "empirical_avg_stretch = np.mean(test_results.stretch_factors)\n",
    "\n",
    "print(\n",
    "    f\" --- cov : {empirical_coverage:.4f} vs nominal : {1-alpha}, for num elements: {len(test_results.conformal_tests)}\"\n",
    ")\n",
    "print(\n",
    "    f\" --- average {empirical_covratio = :.4f} -vs- {covratio = :.4f} (not covered by guarantee)\"\n",
    ")\n",
    "print(f\" --- {empirical_avg_stretch = :.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
