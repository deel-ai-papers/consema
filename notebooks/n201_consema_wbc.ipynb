{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformalization of Segmentation by Margin expansion: WBC dataset\n",
    "\n",
    "- Author: Luca Mossina. IRT Saint ExupÃ©ry, Toulouse, France\n",
    "\n",
    "**Scope**: test the full pipeline for Conformal Prediction on WBC datasets (universeg predictor)\n",
    "\n",
    "- data: wbc. Downloaded to `/tmp/universeg_wbc` by the universeg code (git-cloned via [Makefile](../Makefile))\n",
    "- predictor: universeg\n",
    "- nonconformity score: thresholding, n. of dilations, radius of structuring element\n",
    "\n",
    "Additional material:\n",
    "- Mathematical morphology [wikipedia](*https://en.wikipedia.org/wiki/Mathematical_morphology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from benchmarkerie.datasets import make_universeg_predictions, setup_wbc\n",
    "\n",
    "from consema.conformal import Conformalizer\n",
    "from consema.plots import visualize_false_negatives\n",
    "from consema.morphology import (\n",
    "    dilation_metrics,\n",
    ")\n",
    "from consema.conformal import thresholding_score\n",
    "from consema.plots import plot_margin_and_recovered, visualize_false_negatives\n",
    "from consema.morphology import (\n",
    "    dilation_score_variable_disk,\n",
    "    dilation_score_fixed_disk,\n",
    ")\n",
    "from consema.morphology import (\n",
    "    operator_dilation_sequential,\n",
    "    operator_dilation_disk_radius,\n",
    ")\n",
    "\n",
    "from universeg import universeg  # installed via Makefile\n",
    "\n",
    "model = universeg(pretrained=True)\n",
    "\n",
    "GPUNAME = \"cuda:0\"\n",
    "device_str = GPUNAME if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_str)\n",
    "\n",
    "_ = model.to(device)\n",
    "\n",
    "# RANDOM_SEED = 1\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data, predictors and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"nucleus\"\n",
    "# LABEL = \"cytoplasm\"\n",
    "\n",
    "## high performance predictor\n",
    "# n_support_samples = 48\n",
    "## medium performance predictor\n",
    "n_support_samples = 24\n",
    "# ## lower performance predictor\n",
    "# n_support_samples = 12\n",
    "\n",
    "data_support, data_calib, data_test, support_images, support_labels = setup_wbc(\n",
    "    LABEL,\n",
    "    n_support_samples,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    device=device_str,\n",
    ")\n",
    "\n",
    "LOAD_PREDS = False\n",
    "SAVE_PREDS = False\n",
    "\n",
    "if SAVE_PREDS:\n",
    "    load_dotenv()\n",
    "    PREDS_DIR = os.getenv(\"EXPERIMENTS_DIR\", \"experiments\")\n",
    "else:\n",
    "    PREDS_DIR = None\n",
    "\n",
    "if LOAD_PREDS:\n",
    "    load_dotenv()\n",
    "    PREDS_DIR = os.getenv(\"EXPERIMENTS_DIR\", \"experiments\")\n",
    "    # Load predictions for calibration and test datasets\n",
    "    calib_preds = np.load(f\"{PREDS_DIR}/calib_nsup_{n_support_samples}.npz\")\n",
    "    # test_preds = np.load(f\"{PREDS_DIR}/test.npz\")\n",
    "\n",
    "    calib_images = calib_preds[\"images\"]\n",
    "    calib_gt_masks = calib_preds[\"gt_masks\"]\n",
    "    calib_predictions = calib_preds[\"preds\"]\n",
    "\n",
    "    # test_images = test_preds['images']\n",
    "    # test_gt_masks = test_preds['gt_masks']\n",
    "    # test_predictions = test_preds['preds']\n",
    "\n",
    "    print(\"Calibration predictions loaded.\")\n",
    "    print(\"Test predictions loaded.\")\n",
    "\n",
    "# # Save predictions for calibration and test datasets in single files\n",
    "calib_images, calib_gt_masks, calib_predictions = make_universeg_predictions(\n",
    "    data_calib,\n",
    "    f\"calib_nsup_{n_support_samples}\",\n",
    "    device_str=device_str,\n",
    "    support_images=support_images,\n",
    "    support_labels=support_labels,\n",
    "    universeg_model=model,\n",
    "    save_to=PREDS_DIR,\n",
    ")\n",
    "# make_universeg_predictions(data_test, \"test\", save_to=PREDS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize False Negatives: we want to control their quantity\n",
    "\n",
    "Via conformal prediction, we control how many false negative we will have, on average, in our test inferences (e.g. when deployed in production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it, (image, prediction, gt) in enumerate(\n",
    "    zip(calib_images, calib_predictions, calib_gt_masks)\n",
    "):\n",
    "    if it >= 2:\n",
    "        break\n",
    "    visualize_false_negatives(image[0], gt[0], prediction[0] > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, the **red points** are false negatives, that is, points that belong to the ground-truth masks but were not predicted by the algorithm.\n",
    "\n",
    "Using conformal prediction, we want to \"extend\" the prediction area (in green) with a conformal margin so that we limit our prediction errors, that is, we reduce the number of false negative with high probability at a significance level chosen by the user.\n",
    "\n",
    "The price to pay are more false positives: in this case, we can imagine that false positives push the users to be more conservative and they are \"safe\" errors.\n",
    "\n",
    "If there are too many false positives, then the prediction becomes operationally useless; this tradeoff is controlled by the user and their predictive model: worse models will have more false negatives, hence larger conformal margins. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonconformity scores as held-out errors\n",
    "\n",
    "Conformal prediction provides a prediction sets that, on average, is statistically valid at a confidence level set by the user.\n",
    "Concretely, the standard approach is known as \"split conformal prediction\", where a part the training data is held out exclusively to compute **prediction errors known as nonconformity scores**: for each application (classification, regression, etc.) one can find several proposition in the literature.\n",
    "\n",
    "The idea is then to use **held-out data to estimate the errors made in production** (e.g. as computed on the test set) and build a prediction set that contains the ground-truth at a specified confidence level, in a frequentist manner.\n",
    "\n",
    "The interest of CP is getting statistical guarantees on the prediction sets with little hypotheses: the data being exchangeable (or i.i.d.), which implies the errors (i.e. the nonconformity scores) to be exchangeable.\n",
    "\n",
    "The guarantees are:\n",
    "- distribution-free (no hypotheses on the underlying probability distribution of the data)\n",
    "- model-agnostic\n",
    "- finite-sample, that is, non-asymptotic.\n",
    "\n",
    "CP is not the only approach to build prediction sets: e.g. parametric models from the statistics literature  (linear models with gaussian homoskedastic errors).\n",
    "\n",
    "If one is not interested in these theoretical guarantees (distribution-free, finite-sample, model-agnostic) but only in an empirical measure of uncertainty, this process can be done on training data itself: if the ML predictor does not overfit too much and the errors (i.e. scores) are similar to what one has in production, the \"conformal\" prediction sets will be reasonably good (but they may not be large enough to be valid at the specified level)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal definition\n",
    "\n",
    "In this repo, we use the generic formulation of **nested** prediction sets as introduced by [Gupta et al. (2019)](https://www.sciencedirect.com/science/article/abs/pii/S0031320321006725) [(arXiv)](https://arxiv.org/abs/1910.10562).\n",
    "They show how this can be directly linked to an underlying nonconformity score.\n",
    "\n",
    "An example of nested prediction set:\n",
    "$$\n",
    "C_{\\lambda}(X) := [ f(x) - \\lambda, f(x) + \\lambda ]\n",
    "$$\n",
    "\n",
    "The nonconformity score, for a sample $(X_i, Y_i)$:\n",
    "\n",
    "$$\n",
    "\\widehat{\\lambda} = \\text{inf} \\{\\lambda \\in \\Lambda: Y_i \\in  C_{\\lambda}(X)\\}\n",
    "$$\n",
    "\n",
    "In words, the nonconformity score is the smallest parameter value such that the prediction set contains the true value $Y_i$.\n",
    "In regression, this boils down to a simple interval.\n",
    "\n",
    "\n",
    "In our case of binary image segmentation, this is extended to sets of points in a discrete space $\\mathcal{Y} \\subseteq \\{0,1\\}^{H \\times W}$\n",
    "\n",
    "$$\n",
    "\\widehat{\\lambda} = \\text{inf} \\{\\lambda \\in \\Lambda: Y_i \\subseteq  C_{\\lambda}(X)\\}\n",
    "$$\n",
    "\n",
    "In words, the nonconformity score is the smallest parameter value such that the extended prediction mask contains all the pixel of the ground-truth mask.\n",
    "Later, we implement a more permission version where only a fraction $\\tau \\in [0,1]$ suffice to consider the truth to be covered (e.g. 99% of the pixel in the gt mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_ = 0\n",
    "# idx_ = 1\n",
    "# idx_ = 2 ## good visual example\n",
    "# idx_ = 3\n",
    "idx_ = 12\n",
    "# idx_ = 10\n",
    "bintruth = calib_gt_masks[idx_] > 0.5\n",
    "binpred = calib_predictions[idx_] > 0.5\n",
    "softpred = calib_predictions[idx_]\n",
    "\n",
    "cov_threshold = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding nonconformity score\n",
    "\n",
    "Sources:\n",
    "- LAC (Least Ambiguous Set-Valued Classifiers), [Sadinle et al. (2019)](https://arxiv.org/abs/1609.00451)\n",
    "- CRC (Conformal Risk Control), [Angelopoulos et al. (2022)](https://arxiv.org/abs/2208.02814)\n",
    "\n",
    "**Thresholding the softmax** or sigmoid scores for **classification** follows from the theory developed in Sadinle et al. (2019), where they work with generic probability distribution, not specifically with neural networks. In this case, the probability estimates (e.g. softmax scores) are known to be not calibrated, and some properties (e.g. optimal size of prediction sets) do not necessarily hold. \n",
    "\n",
    "As for **binary image segmentation** with an underlying pixel-wise classifier, this was introduced as an application of their CRC algorithm by Angelopoulos et al. (2022): they do not explicitly mention nonconformity scores, although it follows immediately from their definition of risk and computation of $\\hat{\\lambda}$, for the case of binary (conformal) losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_threshold, dilated_threshold_mask = thresholding_score(\n",
    "    gt_mask_=bintruth,\n",
    "    soft_pred_mask_=softpred,\n",
    "    coverage_threshold=cov_threshold,\n",
    "    return_dilated_mask=True,\n",
    ")\n",
    "\n",
    "print(f\"{nc_threshold = :.9f}\")\n",
    "metrics = dilation_metrics(dilated_threshold_mask[0], binpred[0])\n",
    "print(f\" --- THRESH: n. added px = {metrics[0]}, stretch = {metrics[1]}\")\n",
    "\n",
    "coverage_tensor = np.multiply(dilated_threshold_mask, bintruth)\n",
    "coverage = np.sum(coverage_tensor) / np.count_nonzero(bintruth)\n",
    "print(f\"{coverage = :.9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_false_negatives(calib_images[idx_][0], bintruth[0], dilated_threshold_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_margin_and_recovered(\n",
    "    binpred[0],\n",
    "    bintruth[0],\n",
    "    dilated_threshold_mask[0],\n",
    "    plot_hard_margin=False,\n",
    "    figsize=(6, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological prediction sets: dilation\n",
    "\n",
    "This is part of the original contribution of the paper: building statistically valid prediction sets under minimal information.\n",
    "- No softmax/sigmoid scores necessary\n",
    "- usable on blackbox predictor, e.g. hidden behind API, MLaaS, etc.\n",
    "- only need a small dataset of labeled, production-like data to measure uncertainty\n",
    "- literature available: mathematical morphology for computer vision (without deep learning)\n",
    "\n",
    "I introduce two cases:\n",
    "- (3x3) structuring element, either square or cross: iteratively dilate the mask as dilated at previous iterations until $\\tau \\times 100 \\%$ of the ground-truth pixels are recovered. Applying several dilations (or other) is also known as **depth** of the dilation. This will constitue the nonconformity score, the higher the worse the prediction was.\n",
    "- variable-size disk: as above, but only apply one dilation to the predicted mask, with the radius of the disk increasing at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se_params = dict(strict_radius=True)  # [3 X 3] cross\n",
    "# se_params = dict(strict_radius=False)  # [3 X 3] square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative dilations\n",
    "\n",
    "Nonconcormity score = depth, or number of repeated dilations.\n",
    "- Using fixed-size structuring element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Fixed disk\n",
    "nc_fixed = dilation_score_fixed_disk(\n",
    "    gt_mask_=bintruth[0],\n",
    "    pred_mask_=binpred[0],\n",
    "    se_params_=se_params,\n",
    "    coverage_threshold=cov_threshold,\n",
    ")\n",
    "print(f\"{nc_fixed = }\")\n",
    "\n",
    "\n",
    "dilated_mask_fixed = operator_dilation_sequential(\n",
    "    input_mask=binpred[0], operator_parameter=nc_fixed, se_params_=se_params\n",
    ")\n",
    "\n",
    "metrics = dilation_metrics(dilated_mask_fixed, binpred[0])\n",
    "print(f\" ---  FIXED: n. added px = {metrics[0]}, stretch = {metrics[1]}\")\n",
    "\n",
    "plot_margin_and_recovered(\n",
    "    binpred[0],\n",
    "    bintruth[0],\n",
    "    dilated_mask_fixed,\n",
    "    input_image=calib_images[idx_][0],\n",
    "    softprediction=softpred[0],\n",
    ")\n",
    "# visualize_false_negatives(calib_images[idx_][0], bintruth[0], dilated_mask_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure with color scheme for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def fig_plot_margin_and_recovered(\n",
    "    predicted_mask: np.ndarray,\n",
    "    ground_truth_mask: np.ndarray,\n",
    "    dilated_mask: np.ndarray,\n",
    "    # margin: Optional[np.ndarray] = None,\n",
    "    input_image: Optional[np.ndarray] = None,\n",
    "    softprediction: Optional[np.ndarray] = None,\n",
    "    plot_hard_margin: Optional[bool] = False,\n",
    "    figsize: Optional[tuple] = None,\n",
    "):\n",
    "    if isinstance(predicted_mask, torch.Tensor):\n",
    "        predicted_mask = predicted_mask.cpu().numpy()\n",
    "    if isinstance(ground_truth_mask, torch.Tensor):\n",
    "        ground_truth_mask = ground_truth_mask.cpu().numpy()\n",
    "    if isinstance(dilated_mask, torch.Tensor):\n",
    "        dilated_mask = dilated_mask.cpu().numpy()\n",
    "\n",
    "    nplots = 4\n",
    "    if input_image is not None:\n",
    "        nplots += 1\n",
    "    if softprediction is not None:\n",
    "        nplots += 1\n",
    "\n",
    "    margin = np.logical_xor(dilated_mask, predicted_mask)\n",
    "\n",
    "    ## for readability in paper, crop the image.\n",
    "    ## DANGER: assumes there is nothing going on in this region\n",
    "    crop = 15\n",
    "    ground_truth_mask = ground_truth_mask[crop:-crop, crop:-crop]\n",
    "    predicted_mask = predicted_mask[crop:-crop, crop:-crop]\n",
    "    dilated_mask = dilated_mask[crop:-crop, crop:-crop]\n",
    "    margin = margin[crop:-crop, crop:-crop]\n",
    "\n",
    "    ## do not crop input image, soft pred\n",
    "    # if input_image is not None:\n",
    "    #     input_image = input_image[crop:-crop, crop:-crop]\n",
    "\n",
    "    recovered = np.where(\n",
    "        (ground_truth_mask == 1) & (predicted_mask == 0) & (dilated_mask == 1), 1, 0\n",
    "    )\n",
    "    not_recovered = np.where(\n",
    "        (ground_truth_mask == 1) & (predicted_mask == 0) & (dilated_mask == 0), 666, 0\n",
    "    )\n",
    "\n",
    "    if recovered.sum() == 0:\n",
    "        print(\"No pixels were recovered\")\n",
    "        # return\n",
    "\n",
    "    recovered_rgba = np.zeros((*recovered.shape, 4))\n",
    "    # (X,X,X,1) for 1 with full opacity\n",
    "    recovered_rgba[recovered == 1] = [1, 0, 0, 1]\n",
    "    recovered_rgba[recovered == 0] = [0, 0, 0, 0]  # Transparent for value 0\n",
    "    recovered_rgba[not_recovered == 666] = [0, 100 / 255, 0, 1]\n",
    "\n",
    "    if plot_hard_margin:\n",
    "        margin = np.where(margin > 0, 1, 0)\n",
    "\n",
    "    figsize = (5 * nplots, 6)\n",
    "    fig, axes = plt.subplots(1, nplots, figsize=figsize, dpi=200)\n",
    "\n",
    "    ## === (1) Ground-truth mask\n",
    "    gt_color = np.array((216, 27, 96)) / 255\n",
    "    gt_rgba = np.zeros((*ground_truth_mask.shape, 4))\n",
    "    gt_rgba[ground_truth_mask == 1] = [gt_color[0], gt_color[1], gt_color[2], 1]\n",
    "    gt_rgba[ground_truth_mask == 0] = [1, 1, 1, 1]  # White for value 0\n",
    "\n",
    "    axes[0].imshow(gt_rgba, interpolation=\"none\")\n",
    "    # axes[0].set_title(\"Ground-truth mask\")\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "\n",
    "    ## === (2) Predicted mask\n",
    "    pred_color = np.array((30, 136, 229)) / 255\n",
    "    pred_rgba = np.zeros((*predicted_mask.shape, 4))\n",
    "    pred_rgba[predicted_mask == 1] = [pred_color[0], pred_color[1], pred_color[2], 0.75]\n",
    "    pred_rgba[predicted_mask == 0] = [1, 1, 1, 1]  # White for value 0\n",
    "\n",
    "    axes[1].imshow(pred_rgba, interpolation=\"none\")\n",
    "    # axes[1].set_title(\"Predicted mask\")\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "    ## === (3) Intersection of gt and pred: intersection in true_pos_color, the others as gt or pred respectively\n",
    "    true_pos_color = np.array((120, 94, 240)) / 255\n",
    "    intersection_rgba = np.zeros((*ground_truth_mask.shape, 4))\n",
    "    intersection_rgba[(ground_truth_mask == 1) & (predicted_mask == 1)] = [\n",
    "        true_pos_color[0],\n",
    "        true_pos_color[1],\n",
    "        true_pos_color[2],\n",
    "        0.8,\n",
    "    ]\n",
    "    # false negative in gt_color\n",
    "    intersection_rgba[(ground_truth_mask == 1) & (predicted_mask == 0)] = [\n",
    "        gt_color[0],\n",
    "        gt_color[1],\n",
    "        gt_color[2],\n",
    "        1,\n",
    "    ]\n",
    "    # false positive in pred_color\n",
    "    intersection_rgba[(ground_truth_mask == 0) & (predicted_mask == 1)] = [\n",
    "        pred_color[0],\n",
    "        pred_color[1],\n",
    "        pred_color[2],\n",
    "        0.75,\n",
    "    ]\n",
    "\n",
    "    axes[2].imshow(intersection_rgba, interpolation=\"none\")\n",
    "    # axes[2].set_title(\"Intersection\")\n",
    "    axes[2].set_xticks([])\n",
    "    axes[2].set_yticks([])\n",
    "\n",
    "    ## === (4) Dilated mask:\n",
    "    ## pred_mask in \"gainsboro\", margin in pred_color with alpha=0.5, recovered in orange with hatching\n",
    "    recov_color = np.array((254, 97, 0)) / 255\n",
    "    dilated_rgba = np.zeros((*dilated_mask.shape, 4))\n",
    "    dilated_rgba[margin == 1] = [pred_color[0], pred_color[1], pred_color[2], 0.5]\n",
    "    dilated_rgba[recovered == 1] = [recov_color[0], recov_color[1], recov_color[2], 1]\n",
    "    # dilated_rgba[predicted_mask == 1] = [0.86, 0.86, 0.86, 1]\n",
    "    dilated_rgba[predicted_mask == 1] = [\n",
    "        true_pos_color[0],\n",
    "        true_pos_color[1],\n",
    "        true_pos_color[2],\n",
    "        0.8,\n",
    "    ]\n",
    "\n",
    "    axes[3].imshow(dilated_rgba, interpolation=\"none\")\n",
    "    # axes[3].set_title(\"Dilated mask\")\n",
    "    axes[3].set_xticks([])\n",
    "    axes[3].set_yticks([])\n",
    "\n",
    "    ## if input_image is not None, plot it\n",
    "    if input_image is not None:\n",
    "        axes[4].imshow(input_image, cmap=\"Greys_r\", interpolation=\"none\")\n",
    "        # axes[4].set_title(\"Input image\")\n",
    "        axes[4].set_xticks([])\n",
    "        axes[4].set_yticks([])\n",
    "        # axes[4].set_xlabel(\"Input image\")\n",
    "        ## if softprediction is not None, plot it\n",
    "        if softprediction is not None:\n",
    "            im = axes[5].imshow(softprediction, cmap=\"viridis\", interpolation=\"none\")\n",
    "            axes[5].set_xticks([])\n",
    "            axes[5].set_yticks([])\n",
    "            divider = make_axes_locatable(axes[5])\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cbar = fig.colorbar(im, cax=cax, orientation=\"vertical\")\n",
    "            cbar.ax.tick_params(\n",
    "                labelsize=16\n",
    "            )  # Increase the font size of the colorbar labels\n",
    "            cbar.set_ticks([0, 0.5, 1])  # Set the ticks to 0, 0.5, and 1\n",
    "            # cbar.set_label('Color Intensity')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # Save individual subplots\n",
    "        fig_filenames = [\n",
    "            \"figures/wbc_nc_margin_01_gt.png\",\n",
    "            \"figures/wbc_nc_margin_02_pred.png\",\n",
    "            \"figures/wbc_nc_margin_03_intersection.png\",\n",
    "            \"figures/wbc_nc_margin_04_dilated.png\",\n",
    "            \"figures/wbc_nc_margin_05_input.png\",\n",
    "            \"figures/wbc_nc_margin_06_soft_prediction.png\",\n",
    "        ]\n",
    "        for i, ax in enumerate(axes):\n",
    "            extent = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "            fig.savefig(\n",
    "                fig_filenames[i],\n",
    "                bbox_inches=extent.expanded(1.025, 1.025),\n",
    "                pad_inches=0.08,\n",
    "                dpi=200,\n",
    "            )\n",
    "\n",
    "        # Save the last figure with the colorbar\n",
    "        extent = axes[5].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        fig.savefig(\n",
    "            \"figures/wbc_nc_margin_06_soft_prediction_with_colorbar.png\",\n",
    "            bbox_inches=extent.expanded(\n",
    "                1.5, 1.10\n",
    "            ),  # Adjust the expansion to include the colorbar\n",
    "            pad_inches=0.08,\n",
    "            dpi=200,\n",
    "        )\n",
    "\n",
    "\n",
    "fig_plot_margin_and_recovered(\n",
    "    binpred[0],\n",
    "    bintruth[0],\n",
    "    dilated_mask_fixed,\n",
    "    input_image=calib_images[idx_][0],\n",
    "    softprediction=softpred[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable-size disk as structuring element\n",
    "\n",
    "Instead of repeating dilations incrementally, on can obtain a similar results modifying the radius of the structuring element used for dilations.\n",
    "\n",
    "Computationally, it should be worse than fixed-size for big radii: a naive implementation requires a number a computations that grows quadratically with the size (H x W) of the structuring element.\n",
    "\n",
    "For binary dilations (our case), one can use a convolution followed by a max: this can be a good option if working directly with torch and tensors; with large images, we could expect comp. gains via gpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Variable disk\n",
    "nc_variable = dilation_score_variable_disk(\n",
    "    gt_mask_=bintruth[0],\n",
    "    pred_mask_=binpred[0],\n",
    "    se_params_=se_params,\n",
    "    coverage_threshold=cov_threshold,\n",
    ")\n",
    "print(f\"{nc_variable = }\")\n",
    "\n",
    "dilated_mask_variable = operator_dilation_disk_radius(\n",
    "    binpred[0], nc_variable, se_params\n",
    ")\n",
    "\n",
    "visualize_false_negatives(calib_images[idx_][0], bintruth[0], dilated_mask_variable)\n",
    "\n",
    "metrics = dilation_metrics(dilated_mask_variable, binpred[0])\n",
    "print(f\" ---  VARIA: n. added px = {metrics[0]}, stretch = {metrics[1]}\")\n",
    "plot_margin_and_recovered(binpred[0], bintruth[0], dilated_mask_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformal loop: compute scores and quantiles\n",
    "\n",
    "Conformal prediction (CP) is usually presented as a predictive method to build statistically valid prediction sets (or intervals) that will contain, with high probability, the true value of a target $Y$ being predicted by some ML model as $\\hat{Y} = \\hat{f}(X)$; the features X could be tabular data, images, etc.\n",
    "\n",
    "However, we have another useful piece of information: the actual errors (nonconformity scores), their size, their distribution.\n",
    "CP can also be used as a diagnostic tool: the users choose a score (or make their own), a tolerable risk level, and then they could:\n",
    "- compare several architectures, trained on the same data: the one with the smallest scores (and prediction set) could be preferable to another with slightly better performance metrics (precision, mAP, etc.)\n",
    "- interpret the errors: in production, how and where the model errs.\n",
    "- interpret the size and shape of the prediction set: for regression or classification, this is the width and cardinality or pred. sets. For segmentation or object detection, this could be the size of the conformal margins, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Split conformal prediction procedure:\n",
    "\n",
    "\n",
    "1. Setup a pre-trained model, or train your own\n",
    "2. setup a parametrized prediction set (hence a nonconformity score): $C_{\\lambda}(X)$\n",
    "3. Fix an acceptable error probability $\\alpha$, also called \"risk\", \"nominal error\", \"nominal risk\", etc.\n",
    "- can be written as $\\epsilon$\n",
    "- $1-\\alpha$ is known as the (nominal) coverage of our conformalized predictor: with confidence $1-\\alpha$, the sets will contain the true value of $Y$ (this is a frequentist object, so some care is necessary when building and interpreting prediction sets).\n",
    "4. Get some **production-like** data $D_{\\text{cal}}$, often called \"calibration data\": labeled data, not used during training, that represents the data distribution fed into your model when deployed in production\n",
    "5. Compute nonconformity scores $r(X,Y)$ on $D_{\\text{cal}}$\n",
    "6. Compute the **adjusted** empirical quantile of order $(1-\\alpha)(1+\\frac{1}{n})$\n",
    "- sort the scores in ascending order\n",
    "- compute the quantile as $\\hat{\\lambda_{\\alpha}} = \\lceil (1 - \\alpha)(n+1) \\rceil$-th largest score\n",
    "7. At inference, compute $C_{\\hat{\\lambda}}(X)$ by plugging $\\hat{\\lambda_{\\alpha}}$ into $C_{\\lambda}(X)$ \n",
    "\n",
    "Note that $C_{\\lambda}(X)$ can be *any* prediction set, as long as the they are nested:\n",
    "- $C_{\\lambda_0}(X) \\subseteq C_{\\lambda_1}(X)$ for all $\\lambda_0 \\leq \\lambda_1$\n",
    "- as $\\lambda$ grows, so does the prediction set. \n",
    "- In the worst-case scenario, we can retrieve the trivial set $C_{\\lambda_{max}}(X) = \\mathcal{Y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize margin: use a gradient to show successive dilations and recovered pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consema.plots import margin_gradient_visu\n",
    "\n",
    "margin_var = margin_gradient_visu(\n",
    "    binpred[0], \"variable_disk\", 10, None, False, se_params\n",
    ")\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].imshow(margin_var, cmap=\"cividis\", interpolation=\"none\")\n",
    "margin_fixed = margin_gradient_visu(binpred[0], \"fixed_disk\", 10, None, True, se_params)\n",
    "ax[1].imshow(margin_fixed, cmap=\"cividis\", interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from consema.conformal import recovered_pixels_bin_array\n",
    "\n",
    "_grad = margin_gradient_visu(binpred[0], \"variable_disk\", 10, 20, True, se_params)\n",
    "\n",
    "# Assuming _grad is your H x W array\n",
    "H, W = _grad.shape\n",
    "rgba_image = np.zeros((H, W, 4), dtype=np.uint8)  # Create an RGBA array\n",
    "\n",
    "# Normalize the gradient to the range [0, 1]\n",
    "normalized_grad = _grad / np.max(_grad)\n",
    "\n",
    "# Set all pixels that are non-zero in the recovered mask to red with full opacity\n",
    "recovered = recovered_pixels_bin_array(bintruth[0], binpred[0], dilated_mask_variable)\n",
    "\n",
    "# Define blending factor and colors\n",
    "alpha_blend = 0.7  # Controls red intensity (0 = no red, 1 = fully red)\n",
    "\n",
    "# Assign colors: white for zeros, blue for non-zero entries\n",
    "nonmargin_indices = np.where(_grad > 0)\n",
    "rgba_image[..., 0] = (1 - normalized_grad) * 255  # Red channel\n",
    "rgba_image[..., 1] = (1 - normalized_grad) * 255  # Green channel\n",
    "rgba_image[..., 2] = 255  # Blue channel\n",
    "rgba_image[..., 3] = (normalized_grad * 255).astype(\n",
    "    np.uint8\n",
    ")  # Alpha channel (transparency)\n",
    "\n",
    "# Blend red for recovered pixels\n",
    "recovered_indices = np.where(recovered == 1)\n",
    "rgba_image[recovered_indices] = (\n",
    "    alpha_blend * np.array([255, 0, 0, 255])  # Red with full opacity\n",
    "    + (1 - alpha_blend) * rgba_image[recovered_indices]\n",
    ").astype(np.uint8)\n",
    "\n",
    "# Visualize the RGBA image\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 5))\n",
    "\n",
    "# Plot ground truth mask on the left\n",
    "ax[0].imshow(bintruth[0], cmap=\"gray\", interpolation=\"none\")\n",
    "ax[0].set_title(\"Ground-truth mask\", fontsize=10)\n",
    "# ax[0].axis(\"off\")\n",
    "\n",
    "# Plot softmax prediction\n",
    "ax[1].imshow(softpred[0], cmap=\"viridis\", interpolation=\"none\")\n",
    "ax[1].set_title(\"Softmax Prediction\", fontsize=10)\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "# plot hard predicted mask\n",
    "ax[2].imshow(binpred[0], cmap=\"gray\", interpolation=\"none\")\n",
    "# ax[2].imshow(binpred[0], cmap=\"Greens\", interpolation=\"none\")\n",
    "ax[2].set_title(\"Predicted mask\", fontsize=10)\n",
    "ax[2].get_yaxis().set_visible(False)\n",
    "\n",
    "# Plot RGBA image on the right\n",
    "ax[3].imshow(rgba_image, interpolation=\"none\")\n",
    "ax[3].set_title(\"Recovered Pixels and Gradient\", fontsize=10)\n",
    "ax[3].get_yaxis().set_visible(False)\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"red\", edgecolor=\"red\", label=\"Recovered\"),\n",
    "    Patch(facecolor=\"blue\", edgecolor=\"blue\", label=\"Pred + Margin\"),\n",
    "]\n",
    "\n",
    "ax[3].legend(\n",
    "    handles=legend_elements, fontsize=8, loc=\"center left\", bbox_to_anchor=(1, 0.8)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup conformalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarkerie.models import UniversegInferenceWrap\n",
    "\n",
    "inferencer = UniversegInferenceWrap(\n",
    "    model=model,\n",
    "    support_images=support_images,\n",
    "    support_labels=support_labels,\n",
    "    device=device,\n",
    "    return_numpy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup conformal parameters\n",
    "- `covratio` $\\in (0,1)$ (coverage ratio): how many ground-truth pixels must be covered in each image to be considered a success\n",
    "- `alpha` $ \\in (0,1)$ (nominal risk): on average, how many inferences can be wrong (but we don't say by how much)\n",
    "\n",
    "During conformalization, the nonconformity scores tell\n",
    "- how many dilations, or \n",
    "- how big the structuring element (e.g. disk), or\n",
    "- which threshold $\\in (0,1)$\n",
    "\n",
    "was necessary to achieve the specified `covratio`. If `covratio = 1`, then 100% of the ground-truth pixels must be captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covratio = 0.99999\n",
    "covratio = 0.999\n",
    "# covratio = 0.9\n",
    "# covratio = 1.0\n",
    "\n",
    "# alpha = 0.90\n",
    "# alpha = 0.50\n",
    "alpha = 0.10\n",
    "# alpha = 0.07\n",
    "# alpha = 0.80  # BAD just for testing\n",
    "\n",
    "score_funcs = [\"fixed_disk\", \"variable_disk\", \"thresholding\"]\n",
    "chosen_nc_score = score_funcs[0]\n",
    "# chosen_nc_score = score_funcs[1]\n",
    "# chosen_nc_score = score_funcs[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute nonconformity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" --- n calibration points: {len(data_calib)}\")\n",
    "\n",
    "cpred = Conformalizer(\n",
    "    inferencer=inferencer,\n",
    "    nonconformity_function_name=chosen_nc_score,\n",
    "    structuring_element_params=se_params,\n",
    ")\n",
    "\n",
    "confo_resu = cpred.compute_nonconformity_scores(data_calib, covratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute conformalizing empirical quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" --- Required coverage ratio = {covratio}\")\n",
    "print(f\" --- Probability of succes on test = {1 - alpha}\")\n",
    "print(f\" --- Chosen nonconformity score: {chosen_nc_score}\")\n",
    "# cpred.plot_nc_scores(confo_resu[\"nonconformity\"], alpha)\n",
    "cpred.plot_nc_scores(alpha_risk=alpha)\n",
    "cpred.plot_nc_scores_frequency(alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics of conformal prediction sets on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" --- Required coverage ratio = {covratio}\")\n",
    "print(f\" --- Probability of succes on test = {1 - alpha}\")\n",
    "print()\n",
    "test_preds = cpred.test_inferences(data_test)\n",
    "test_results = cpred.test_conformalization(test_preds, alpha, covratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_coverage = np.mean(test_results.conformal_tests)\n",
    "empirical_covratio = np.mean(test_results.empirical_covratios)\n",
    "empirical_avg_add_pixels = np.mean(test_results.added_pixels)\n",
    "empirical_avg_stretch = np.mean(test_results.stretch_factors)\n",
    "\n",
    "print(\n",
    "    f\" --- {empirical_coverage = :.4f} vs nominal : {1-alpha}, for num elements: {len(test_results.conformal_tests)}\"\n",
    ")\n",
    "print(f\" --- {empirical_covratio = :.4f} -vs- {covratio = :.4f}\")\n",
    "print(f\" --- {empirical_avg_add_pixels = :.4f}\")\n",
    "print(f\" --- {empirical_avg_stretch = :.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
